import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error, r2_score
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping
from scikeras.wrappers import KerasRegressor
import numpy as np
import joblib
import matplotlib.pyplot as plt

# === ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ===
data = pd.read_excel("bands_sentinel_train.xlsx")
X = data[["Band1", "Band2", "Band3", "Band4"]].values
y = data[["Blue (B1)", "Green (B2)", "Red (B3)", "NIR (B4)"]].values

# === ‡πÅ‡∏ö‡πà‡∏á‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ===
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# === Scaling ===
scaler_X = MinMaxScaler()
scaler_y = MinMaxScaler()

X_train_scaled = scaler_X.fit_transform(X_train)
X_test_scaled = scaler_X.transform(X_test)
y_train_scaled = scaler_y.fit_transform(y_train)
y_test_scaled = scaler_y.transform(y_test)

# === ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• Keras ===
def build_model():
    model = Sequential([
        Dense(128, activation='relu', input_shape=(4,)),
        Dropout(0.2),
        Dense(64, activation='relu'),
        Dropout(0.2),
        Dense(32, activation='relu'),
        Dense(4, activation='sigmoid')
    ])
    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')
    return model

# === ‡∏´‡πà‡∏≠‡∏î‡πâ‡∏ß‡∏¢ scikeras ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏õ‡πá‡∏ô pkl ‡πÑ‡∏î‡πâ ===
wrapper = KerasRegressor(
    model=build_model,
    epochs=300,
    batch_size=16,
    validation_split=0.2,
    verbose=1,
    callbacks=[EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)]
)

# === ‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• ===
history = wrapper.fit(X_train_scaled, y_train_scaled)

# === ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô ===
y_pred_scaled = wrapper.predict(X_test_scaled)
y_pred = scaler_y.inverse_transform(y_pred_scaled)

rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)
print(f"\n‚úÖ RMSE: {rmse:.3f}")
print(f"‚úÖ R¬≤: {r2:.3f}")

# === ‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏£‡∏≤‡∏ü Loss ===
plt.figure(figsize=(8,5))
plt.plot(history.history_['loss'], label='Training Loss')
plt.plot(history.history_['val_loss'], label='Validation Loss')
plt.title('Loss vs Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('MSE')
plt.legend()
plt.grid(True)
plt.show()

# === ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏õ‡πá‡∏ô .pkl ===
joblib.dump(wrapper, "deep_reflectance_model.pkl")

# === ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å scaler ‡πÄ‡∏õ‡πá‡∏ô .save ===
joblib.dump(scaler_X, "scaler_X.save")
joblib.dump(scaler_y, "scaler_y.save")

print("üíæ ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ñ‡∏π‡∏Å‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏õ‡πá‡∏ô deep_reflectance_model.pkl")
print("üíæ ‡∏ï‡∏±‡∏ß‡∏™‡πÄ‡∏Å‡∏•‡∏ñ‡∏π‡∏Å‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏õ‡πá‡∏ô scaler_X.save ‡πÅ‡∏•‡∏∞ scaler_y.save")
